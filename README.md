# ğŸ¤– Agentic RAG System

A comprehensive Retrieval-Augmented Generation (RAG) system built with FastAPI, React, and modern AI technologies. This system allows you to upload documents, generate embeddings, and ask questions about your content using advanced language models.

## ğŸ—ï¸ Architecture

```
Agentic_RAG_System/
â”œâ”€â”€ backend/                 # FastAPI backend service
â”‚   â”œâ”€â”€ api/                # API routes and endpoints
â”‚   â”œâ”€â”€ core/               # Core configuration and settings
â”‚   â”œâ”€â”€ services/           # Business logic services
â”‚   â”œâ”€â”€ utils/              # Utility functions and logging
â”‚   â”œâ”€â”€ sample_documents/   # Test PDF documents
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # React frontend application
â”‚   â”œâ”€â”€ src/                # Source code
â”‚   â”œâ”€â”€ public/             # Static assets
â”‚   â””â”€â”€ package.json        # Node.js dependencies
â”œâ”€â”€ docs/                   # Documentation
â”‚   â””â”€â”€ TESTING_GUIDE.md    # Comprehensive testing guide
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â””â”€â”€ create_test_pdfs.py # PDF generation script
â””â”€â”€ README.md              # This file
```

## âœ¨ Features

- Document ingestion (PDF â†’ chunks â†’ embeddings)
- RAG pipeline with OpenAI + Pinecone
- FastAPI endpoints for chat and files
- React UI with Upload/Chat/Status tabs
- Delete and Replace (Update) file vectors from UI

## ğŸš€ Run

### Backend
```
cd backend
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
python main.py
```

Ensure `.env` in `backend/` is configured:
```
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OPENAI_MODEL=gpt-3.5-turbo

PINECONE_API_KEY=pcsk-...
PINECONE_INDEX_NAME=rag-documents
# Region must match your Pinecone index host (e.g., ap-southeast-1)
PINECONE_ENVIRONMENT=ap-southeast-1
```

### Frontend
```
cd frontend
npm install
npm run dev
```

- Frontend: http://localhost:5173
- API docs: http://localhost:8000/docs

## ğŸ§ª Test

- Use Upload tab to add PDFs from `backend/sample_documents/`
- Ask questions in Chat
- Manage vectors with Replace/Delete buttons after upload completes
- Status tab shows Vector DB and LLM health

## ğŸ”§ Troubleshooting

### Pinecone SSL / "Max retries exceeded ... SSLError(FileNotFoundError)"
- Create a fresh venv with modern Python (prefer 3.11+)
- Install HTTP stack with certs:
```
pip install --upgrade pip certifi requests "urllib3<2.2"
```
- We set `SSL_CERT_FILE`/`REQUESTS_CA_BUNDLE` to `certifi.where()` in `backend/core/config.py` automatically.
- Restart backend.

### Region mismatch
- If your Pinecone index host looks like `...aped...`, set `PINECONE_ENVIRONMENT=ap-southeast-1` (or the region where your index resides).
- `backend/services/vectordb_service.py` uses `PINECONE_ENVIRONMENT` for `ServerlessSpec`.

### Missing deps (e.g., `ModuleNotFoundError: langgraph`)
- Activate venv and run:
```
pip install -r requirements.txt
```

### Health shows Degraded
- Open http://localhost:8000/files/health and verify:
  - `vectordb: true` (Pinecone reachable and index OK)
  - `llm: true` (OpenAI reachable)
- Fix `.env` keys or region and restart.

## ğŸ“š API Endpoints

- `POST /chat/` â€“ query with RAG
- `GET /health` â€“ basic API health
- `POST /files/add_file` â€“ upload/process PDF
- `PUT /files/update_file/{file_id}` â€“ replace vectors with a new PDF
- `DELETE /files/delete_file/{file_id}` â€“ remove vectors by file
- `GET /files/health` â€“ RAG service health (LLM + Vector DB)

## ğŸ“– Docs

- See `docs/TESTING_GUIDE.md` for detailed testing scenarios and datasets.